{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2\n",
    "구글 colab 환경에서 진행.  \n",
    "\n",
    "모델 성능은 **wandb.ai**에 기록  \n",
    "\n",
    "기쁨, 슬픔, 당황, 분노, 중립 각 감정마다 30명의 성우, 데이터 30개씩 학습 진행.  \n",
    "\n",
    "음성 데이터 증강을 하기 전 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(927)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, Conv2D, MaxPool2D, ZeroPadding2D, BatchNormalization, Input, DepthwiseConv2D, Add, LeakyReLU, ReLU\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(927)\n",
    "\n",
    "\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, Conv2D, MaxPool2D, ZeroPadding2D, BatchNormalization, Input, DepthwiseConv2D, Add, LeakyReLU, ReLU\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = 'cp2'\n",
    "wandb_group = '2hg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emotion_pred:\n",
    "    def __init__(self, size, pad_size, repeat_size, sr, epochs, batch_size):\n",
    "        self.size = size\n",
    "        self.pad_size = pad_size\n",
    "        self.repeat_size = repeat_size\n",
    "        self.sr = sr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        wandb.config.size = self.size\n",
    "        wandb.config.pad_size = self.pad_size\n",
    "        wandb.config.repeat_size = self.repeat_size\n",
    "        wandb.config.sr = self.sr\n",
    "        wandb.config.epochs = self.epochs\n",
    "        wandb.config.batch_size = self.batch_size\n",
    "\n",
    "\n",
    "    def load_audio(self, file_names, target, path):\n",
    "        audios = []\n",
    "        for audio in tqdm(file_names):\n",
    "            au_audio, _ = librosa.load(path+audio, sr=self.sr)\n",
    "            audio_array = np.array(au_audio)\n",
    "            audios.append(audio_array)\n",
    "        audios = np.array(audios)\n",
    "        target = target.copy()\n",
    "\n",
    "        return audios, target\n",
    "\n",
    "\n",
    "    def random_pad(mels, pad_size, mfcc=True):\n",
    "        pad_width = pad_size - mels.shape[1]\n",
    "        rand = np.random.rand()\n",
    "        left = int(pad_width * rand)\n",
    "        right = pad_width - left\n",
    "        \n",
    "        if mfcc:\n",
    "            mels = np.pad(mels, pad_width=((0,0), (left, right)), mode='constant')\n",
    "            local_max, local_min = mels.max(), mels.min()\n",
    "            mels = (mels - local_min)/(local_max - local_min)\n",
    "        else:\n",
    "            local_max, local_min = mels.max(), mels.min()\n",
    "            mels = (mels - local_min)/(local_max - local_min)\n",
    "            mels = np.pad(mels, pad_width=((0,0), (left, right)), mode='constant')\n",
    "\n",
    "\n",
    "        return mels\n",
    "\n",
    "    \n",
    "    \n",
    "    def train_mels_mfcc(self, audio):\n",
    "        audio_mels = []\n",
    "        audio_mfcc = []\n",
    "\n",
    "        for y in tqdm(audio):\n",
    "            mels = librosa.feature.melspectrogram(y, sr=self.sr, n_mels=self.size)\n",
    "            mels = librosa.power_to_db(mels, ref=np.max)\n",
    "\n",
    "            mfcc = librosa.feature.mfcc(y, sr=self.sr, n_mfcc=self.size)\n",
    "\n",
    "            for i in range(self.repeat_size):\n",
    "                audio_mels.append(Emotion_pred.random_pad(mels, pad_size=self.pad_size, mfcc=False))\n",
    "                audio_mfcc.append(Emotion_pred.random_pad(mfcc, pad_size=self.pad_size, mfcc=True))\n",
    "\n",
    "        audio_mels_array = np.array(audio_mels, np.float64)\n",
    "        audio_mfcc_array = np.array(audio_mfcc, np.float64)\n",
    "\n",
    "        print()\n",
    "        print(\"train mels shape: \", audio_mels_array.shape)\n",
    "        print(\"train mfcc shape: \", audio_mfcc_array.shape)\n",
    "        print()\n",
    "\n",
    "        return audio_mels_array, audio_mfcc_array\n",
    "\n",
    "\n",
    "    def test_mels_mfcc(self, audio):\n",
    "        audio_mels = []\n",
    "        audio_mfcc = []\n",
    "\n",
    "        for y in tqdm(audio):\n",
    "            mels = librosa.feature.melspectrogram(y, sr=self.sr, n_mels=self.size)\n",
    "            mels = librosa.power_to_db(mels, ref=np.max)\n",
    "\n",
    "            mfcc = librosa.feature.mfcc(y, sr=self.sr, n_mfcc=self.size)\n",
    "\n",
    "            audio_mels.append(Emotion_pred.random_pad(mels, pad_size=self.pad_size, mfcc=False))\n",
    "            audio_mfcc.append(Emotion_pred.random_pad(mfcc, pad_size=self.pad_size, mfcc=True))\n",
    "\n",
    "        audio_mels_array = np.array(audio_mels, np.float64)\n",
    "        audio_mfcc_array = np.array(audio_mfcc, np.float64)\n",
    "\n",
    "        print()\n",
    "        print(\"test mels shape: \", audio_mels_array.shape)\n",
    "        print(\"test mfcc shape: \", audio_mfcc_array.shape)\n",
    "        print()\n",
    "\n",
    "        return audio_mels_array, audio_mfcc_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def residual_block(self, x, filters_in, filters_out):\n",
    "        self.x = x\n",
    "        self.filters_in = filters_in\n",
    "        self.filters_out = filters_out\n",
    "        \n",
    "        shortcut = self.x\n",
    "        self.x = BatchNormalization()(self.x)\n",
    "        self.x = ReLU()(self.x)\n",
    "        self.x = Conv2D(self.filters_in, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",kernel_initializer='he_normal')(self.x)\n",
    "\n",
    "        self.x = BatchNormalization()(self.x)\n",
    "        self.x = ReLU()(self.x)    \n",
    "        self.x = Conv2D(self.filters_in, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",kernel_initializer='he_normal')(self.x)\n",
    "\n",
    "        self.x = BatchNormalization()(self.x)\n",
    "        self.x = ReLU()(self.x)  \n",
    "        self.x = Conv2D(self.filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",kernel_initializer='he_normal')(self.x)\n",
    "\n",
    "        shortcut_channel = self.x.shape.as_list()[0]\n",
    "        \n",
    "        if shortcut_channel != self.filters_out:\n",
    "            shortcut = Conv2D(self.filters_out, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",kernel_initializer='he_normal')(shortcut)\n",
    "            \n",
    "        self.x = Add()([self.x, shortcut])\n",
    "        return ReLU()(self.x)\n",
    "\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        inputs = tf.keras.layers.Input(shape=(self.size, self.pad_size,1))\n",
    "\n",
    "        outputs = Conv2D(16,(3,3),activation=None,padding='same',kernel_initializer='he_normal')(inputs)\n",
    "        outputs = BatchNormalization()(outputs)\n",
    "        outputs = ReLU()(outputs)\n",
    "        outputs = MaxPool2D((2,2))(outputs)\n",
    "\n",
    "        outputs = Emotion_pred.residual_block(self, outputs, 16, 32)\n",
    "        outputs = MaxPool2D((2,2))(outputs)\n",
    "        outputs = Emotion_pred.residual_block(self, outputs, 32, 32)\n",
    "        outputs = Emotion_pred.residual_block(self, outputs, 32, 32)\n",
    "        #outputs = Emotion_pred.residual_block(self, outputs, 32, 64)\n",
    "        outputs = MaxPool2D((2,2))(outputs)\n",
    "        outputs = Emotion_pred.residual_block(self, outputs, 64, 64)\n",
    "        outputs = Emotion_pred.residual_block(self, outputs, 64, 64)\n",
    "        outputs = MaxPool2D((2,2))(outputs)\n",
    "\n",
    "        outputs = GlobalAveragePooling2D()(outputs)\n",
    "        outputs = Flatten()(outputs)\n",
    "\n",
    "        outputs = Dense(32,activation=None,kernel_initializer='he_normal')(outputs)\n",
    "        outputs = BatchNormalization()(outputs)\n",
    "        outputs = ReLU()(outputs)\n",
    "        outputs = Dropout(0.5)(outputs)\n",
    "\n",
    "        outputs = Dense(5,activation='softmax')(outputs)\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(model_n, size, pad_size, repeat_size, sr, epochs, batch_size):\n",
    "    BASE_PATH = '/content/drive/MyDrive/CP2/'\n",
    "    train_df = pd.read_csv('/content/drive/MyDrive/CP2/Dir_New/train.csv')\n",
    "    test_df = pd.read_csv('/content/drive/MyDrive/CP2/Dir_New/test.csv')\n",
    "    \n",
    "    train_file_names = train_df['file_name'].to_numpy()\n",
    "    test_file_names = test_df['file_name'].to_numpy()\n",
    "    target = train_df['label'].to_numpy()\n",
    "\n",
    "    \n",
    "    model_name = Emotion_pred(size=size, pad_size=pad_size, repeat_size=repeat_size, sr=sr, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    audio_train, target_train = model_name.load_audio(train_file_names, target, path=BASE_PATH+'Dir_New/train/')\n",
    "    audio_test, _ = model_name.load_audio(test_file_names, np.array([None]), path=BASE_PATH+'Dir_New/test/')\n",
    "    \n",
    "    audio_mels_array, audio_mfcc_array = model_name.train_mels_mfcc(audio_train)\n",
    "    audio_mels_array_test, audio_mfcc_array_test = model_name.test_mels_mfcc(audio_test)\n",
    "    repeated_target = np.repeat(train_df['label'].to_numpy(), repeat_size)\n",
    "\n",
    "\n",
    "    acc_list = []\n",
    "    pred_list = []\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    for fold,(train_index, val_index) in enumerate(skf.split(audio_mels_array, repeated_target)):\n",
    "\n",
    "        print(f'\\n********** {fold+1} fold **********')\n",
    "\n",
    "        preds_val_list = []\n",
    "        ### melspectrogram ###\n",
    "        model = model_name.build_model()\n",
    "        x_train, x_val, y_train, y_val = audio_mels_array[train_index], audio_mels_array[val_index], repeated_target[train_index], repeated_target[val_index]\n",
    "        filepath = f\"/content/drive/MyDrive/CP2/DS/{model_n}/{model_n}.res_test_0930_mels_{fold+1}.h5\"\n",
    "        callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min'), WandbCallback()]\n",
    "        history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val,y_val), callbacks=callbacks, verbose=0)\n",
    "        model = load_model(filepath)\n",
    "\n",
    "        preds_val = model.predict(x_val)\n",
    "        preds_val_list.append(preds_val)\n",
    "        preds_val_label = np.argmax(preds_val, axis=1)\n",
    "        pred_list.append(model.predict(audio_mels_array_test))\n",
    "        print(f'mels_model_acc : {accuracy_score(y_val,preds_val_label):.4f}')\n",
    "\n",
    "        ### mfcc ###\n",
    "        model = model_name.build_model()\n",
    "        x_train, x_val, y_train, y_val = audio_mfcc_array[train_index], audio_mfcc_array[val_index], repeated_target[train_index], repeated_target[val_index]\n",
    "        filepath = f\"/content/drive/MyDrive/CP2/DS/{model_n}/{model_n}.res_test_0930_mfcc_{fold+1}.h5\"\n",
    "        callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min'), WandbCallback()]\n",
    "        history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val,y_val), callbacks=callbacks, verbose=0)\n",
    "        model = load_model(filepath)\n",
    "\n",
    "        preds_val = model.predict(x_val)\n",
    "        preds_val_list.append(preds_val)\n",
    "        preds_val_label = np.argmax(preds_val, axis=1)\n",
    "        pred_list.append(model.predict(audio_mfcc_array_test))\n",
    "        print(f'mfcc_model_acc : {accuracy_score(y_val,preds_val_label):.4f}')\n",
    "\n",
    "        ### ensemble ###\n",
    "        val_pred_result = preds_val_list[0].copy()\n",
    "        for i in range(1, len(preds_val_list)):\n",
    "            val_pred_result += preds_val_list[i]\n",
    "        val_pred_label = np.argmax(val_pred_result, axis=1)\n",
    "        en_acc = accuracy_score(y_val,val_pred_label)\n",
    "        acc_list.append(en_acc)\n",
    "        print(f'ensemble_model_acc : {en_acc:.4f}')\n",
    "\n",
    "        print(f'\\n\\nmean_acc : {np.mean(acc_list):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=wandb_project, entity=wandb_group)\n",
    "model7 = start(model_n='model7',size=120, pad_size=450, repeat_size=2, sr=16000, epochs=50, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
